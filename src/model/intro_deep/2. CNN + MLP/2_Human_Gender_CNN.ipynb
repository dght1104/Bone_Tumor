{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"anaconda-cloud":{}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Overview\n- WIKI dataset (face images + gender + age + ...)\n  + Goal: classifying human gender\n  + Input: a 64x64 image\n  + Output: gender (female or male)\n- Defining an CNN+MLP for WIKI dataset\n- Training and evaluating an CNN+MLP","metadata":{}},{"cell_type":"markdown","source":"# Import libraries","metadata":{}},{"cell_type":"code","source":"import keras\nfrom keras.models import Model\nfrom keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom keras.optimizers import Adam\n\nfrom IPython.display import SVG\nfrom tensorflow.keras.utils import model_to_dot \n\nimport time\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T15:28:51.050124Z","iopub.execute_input":"2025-03-25T15:28:51.050684Z","iopub.status.idle":"2025-03-25T15:28:51.057343Z","shell.execute_reply.started":"2025-03-25T15:28:51.050634Z","shell.execute_reply":"2025-03-25T15:28:51.056004Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"num_classes = 2   # male vs. female","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T15:28:51.058840Z","iopub.execute_input":"2025-03-25T15:28:51.059167Z","iopub.status.idle":"2025-03-25T15:28:51.075728Z","shell.execute_reply.started":"2025-03-25T15:28:51.059140Z","shell.execute_reply":"2025-03-25T15:28:51.074855Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# (1) Data","metadata":{}},{"cell_type":"markdown","source":"### Download data at https://drive.google.com/drive/folders/0BxINLo5jshCRYW8xODhNSlkyLTQ?resourcekey=0-RNJvvSSE67Q1bMqQi3A1RQ&usp=sharing\nThis source code and npy files MUST be in the same location","metadata":{}},{"cell_type":"code","source":"x_train = np.load('64_64_11938_4098_train_x_onehot.npy')\ny_train = np.load('64_64_11938_4098_train_y_onehot.npy')\nx_train = np.rot90(x_train, k=3, axes=(1, 2))\n\nx_test = np.load('64_64_5968_4098_val_x_onehot.npy')\ny_test = np.load('64_64_5968_4098_val_y_onehot.npy')\nx_test = np.rot90(x_test, k=3, axes=(1, 2))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T15:28:51.077352Z","iopub.execute_input":"2025-03-25T15:28:51.077741Z","iopub.status.idle":"2025-03-25T15:28:51.116742Z","shell.execute_reply.started":"2025-03-25T15:28:51.077682Z","shell.execute_reply":"2025-03-25T15:28:51.114818Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-9c0f21e0f6e5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'64_64_11938_4098_train_x_onehot.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'64_64_11938_4098_train_y_onehot.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrot90\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'64_64_5968_4098_val_x_onehot.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '64_64_11938_4098_train_x_onehot.npy'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '64_64_11938_4098_train_x_onehot.npy'","output_type":"error"}],"execution_count":5},{"cell_type":"markdown","source":"# (2) Declare model","metadata":{}},{"cell_type":"code","source":"# 64x64 portray image\ninput_image = Input(shape=(64, 64, 1), name='Input')\n\n# conv, pooling layers + dropout\nx = Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu', name='conv1_1')(input_image)\nx = Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu', name='conv1_2')(x)\nx = MaxPooling2D(pool_size=(2, 2), name='pool1')(x)\nx = Dropout(rate=0.2, name='conv_dropout1')(x)\n\nx = Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu', name='conv2_1')(x)\nx = Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu', name='conv2_2')(x)\nx = Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu', name='conv2_3')(x)\nx = MaxPooling2D(pool_size=(2, 2), name='pool2')(x)\nx = Dropout(rate=0.2, name='conv_dropout2')(x)\n\nx = Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu', name='conv3_1')(x)\nx = Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu', name='conv3_2')(x)\nx = Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu', name='conv3_3')(x)\nx = MaxPooling2D(pool_size=(2, 2), name='pool3')(x)\nx = Dropout(rate=0.2, name='conv_dropout3')(x)\n\nx = Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu', name='conv4_1')(x)\nx = Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu', name='conv4_2')(x)\nx = Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu', name='conv4_3')(x)\nx = MaxPooling2D(pool_size=(2, 2), name='pool4')(x)\nx = Dropout(rate=0.2, name='conv_dropout4')(x)\n\nx = Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu', name='conv5_1')(x)\nx = Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu', name='conv5_2')(x)\nx = Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu', name='conv5_3')(x)\nx = MaxPooling2D(pool_size=(2, 2), name='pool5')(x)\nx = Dropout(rate=0.2, name='conv_dropout5')(x)\n\n# similar to the MLP example!\n# matrix ---> vector\nx = Flatten(name='flatten')(x)\n\n# FC layers + dropout\nx = Dense(units=1024, activation='relu', name='fc1')(x)\nx = Dropout(rate=0.2, name='fc_dropout1')(x)\n\nx = Dense(units=1024, activation='relu', name='fc2')(x)\nx = Dropout(rate=0.2, name='fc_dropout2')(x)\n\noutput_label = Dense(units=num_classes, activation='softmax', name='fc3_10ways_softmax')(x)\n\n# define model\nmodel = Model(inputs=input_image, outputs=output_label, name='mnist_mlp')\n\n# print model summary\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T15:28:51.117809Z","iopub.status.idle":"2025-03-25T15:28:51.118183Z","shell.execute_reply":"2025-03-25T15:28:51.118048Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T15:28:51.120118Z","iopub.status.idle":"2025-03-25T15:28:51.120696Z","shell.execute_reply":"2025-03-25T15:28:51.120414Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# (3) Train defined model\n- Note that the training history including loss and accuracy will be save in 'history' variable\n- In case your system runs out of memory (OOM), try to decrease batch size","metadata":{}},{"cell_type":"code","source":"# declare learning rate, loss function, and model metric\nloss = 'categorical_crossentropy'\nlr = 0.0001\nmodel.compile(loss=loss, optimizer=Adam(lr=lr), metrics=['accuracy'])\n\n# train the model\nbatch_size = 128\nepochs = 30\n\nstarting_time = time.time()\nhistory = model.fit(x_train, y_train,\n                    validation_data=(x_test, y_test),\n                    batch_size=batch_size,\n                    epochs=epochs)\nprint('> training time is %.4f minutes' % ((time.time() - starting_time)/60))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T15:28:51.121851Z","iopub.status.idle":"2025-03-25T15:28:51.122434Z","shell.execute_reply":"2025-03-25T15:28:51.122232Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Training time\n- Training time with GTX 1080 is about 2.9352 minutes for 30 epochs\n- Training time with Core i7 is around 109 minutes for 30 epochs","metadata":{}},{"cell_type":"markdown","source":"# (4) Evaluate trained model","metadata":{}},{"cell_type":"code","source":"score = model.evaluate(x_test, y_test)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T15:28:51.123192Z","iopub.status.idle":"2025-03-25T15:28:51.123647Z","shell.execute_reply":"2025-03-25T15:28:51.123497Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def int2gender(num):\n    if num == 0:\n        return 'female'\n    else:\n        return 'male'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T15:28:51.124321Z","iopub.status.idle":"2025-03-25T15:28:51.124765Z","shell.execute_reply":"2025-03-25T15:28:51.124527Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# select a test image randomly\nrandom_test_index = np.random.choice(x_test.shape[0], size=1)[0]\ntest_img = x_test[random_test_index]\ntest_label = np.argmax(y_test[random_test_index])\n\n# predict test image with trained model\npred_label = model.predict(np.expand_dims(test_img, axis=0))\npred_label = np.argmax(pred_label)\n\nplt.imshow(test_img[:, :, 0], cmap='gray')\nplt.title('true label = %s, predicted label = %s' % (int2gender(test_label), int2gender(pred_label)))\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T15:28:51.126080Z","iopub.status.idle":"2025-03-25T15:28:51.126442Z","shell.execute_reply":"2025-03-25T15:28:51.126282Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}